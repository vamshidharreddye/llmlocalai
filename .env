# LLM Configuration
LLM_PROVIDER=ollama
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL=mistral
OLLAMA_EMBED_MODEL=nomic-embed-text

# Uncomment below and fill if you want to use OpenAI instead
# LLM_PROVIDER=openai
# OPENAI_API_KEY=your_key_here
# OPENAI_MODEL=gpt-4o-mini

# Search Configuration
VECTOR_DB_PATH=./vector_store
CHUNK_SIZE=2000
TOP_K_RESULTS=5

# Index Configuration (directories to scan - comma separated)
INDEX_DIRS=./data

# Backend Configuration
BACKEND_HOST=127.0.0.1
BACKEND_PORT=8000
INDEX_DB_PATH=./vector_store
SEARCH_TOP_K=5


FILE_SEARCH_ROOT=C:/Users/VAMSHI/Documents