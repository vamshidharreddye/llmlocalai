# ğŸ¤– Local AI File Chatbot

A powerful, privacy-first desktop AI agent that searches your local files and answers questions using Ollama (local LLM). No data leaves your computer.

[![Python](https://img.shields.io/badge/Python-3.8+-blue.svg)](https://www.python.org)
[![FastAPI](https://img.shields.io/badge/FastAPI-0.104+-green.svg)](https://fastapi.tiangolo.com)
[![License](https://img.shields.io/badge/License-MIT-yellow.svg)](LICENSE)

## ğŸ¯ Features

- ğŸ” **Full-Text & Vector Search** - Find files using semantic search
- ğŸ¤– **Local AI** - Uses Ollama for completely private question answering
- ğŸ“„ **Multiple Formats** - Support for PDF, DOCX, TXT, MD files
- ğŸš€ **Fast** - Instant search and responses
- ğŸ”’ **Private** - Everything stays on your machine
- ğŸ’» **Beautiful UI** - Clean, modern chat interface
- âš¡ **Zero Setup** - One-click launch

## ğŸš€ Quick Start

### Prerequisites
- Python 3.8+
- [Ollama](https://ollama.ai) installed and running
- Windows, macOS, or Linux

### Installation (Windows)

1. **Clone/Download** this repository

2. **Install Python dependencies**:
   ```powershell
   cd backend
   pip install -r requirements.txt
   ```

3. **Start Ollama** (if not already running):
   ```powershell
   ollama serve
   ```

4. **Run the launcher**:
   ```powershell
   # Double-click START.bat  
   # OR
   .\START.ps1
   ```

That's it! Your browser will open to `http://localhost:3000`

## ğŸ“– Usage

### Basic Workflow

1. **Add Your Files**
   - Copy PDFs, Word docs, text files to the `data/` folder
   
2. **Index Files**
   - Click "Reindex Files" button in the chat
   
3. **Ask Questions**
   - Type your question and press Enter
   - Chatbot searches your files and answers

4. **View Sources**
   - See which files were used in the right panel
   - Click filenames to copy their paths

### Example Queries

```
"Summarize the main points from my documents"
"Find all references to machine learning"
"What does the technical specification say about authentication?"
"Which file mentions the API endpoints?"
"Explain the deployment process"
```

## ğŸ“ Project Structure

```
llmlocalai/
â”œâ”€â”€ ğŸ“„ START.bat                    # Windows launcher (batch)
â”œâ”€â”€ ğŸ“„ START.ps1                    # Windows launcher (PowerShell)
â”œâ”€â”€ ğŸŒ index.html                   # Web UI
â”œâ”€â”€ ğŸ“„ server.py                    # UI HTTP server
â”œâ”€â”€ ğŸ“‹ SETUP_GUIDE.md              # Detailed setup guide
â”œâ”€â”€ ğŸ“‹ README.md                    # This file
â”œâ”€â”€ ğŸ“‹ .env                         # Configuration
â”‚
â”œâ”€â”€ ğŸ“‚ backend/
â”‚   â”œâ”€â”€ ğŸ app.py                  # FastAPI main application
â”‚   â”œâ”€â”€ ğŸ” indexer.py              # File indexing & embedding
â”‚   â”œâ”€â”€ ğŸ” search.py               # Vector search
â”‚   â”œâ”€â”€ ğŸ¤– llm_client.py           # Ollama integration
â”‚   â”œâ”€â”€ ğŸ“„ file_extractor.py       # PDF/DOCX/TXT parsing
â”‚   â””â”€â”€ ğŸ“‹ requirements.txt         # Python dependencies
â”‚
â”œâ”€â”€ ğŸ“‚ data/                        # Your files go here â­
â”‚   â”œâ”€â”€ test_docs/
â”‚   â””â”€â”€ README.md
â”‚
â””â”€â”€ ğŸ“‚ vector_store/               # Embeddings database (auto-created)
```

## âš™ï¸ Configuration

Edit `.env` file to customize behavior:

```ini
# LLM Provider
LLM_PROVIDER=ollama
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL=mistral  # Can use: mistral, llama2, neural-chat, etc.

# Search Settings
VECTOR_DB_PATH=./vector_store
CHUNK_SIZE=2000
TOP_K_RESULTS=5

# Directories to Index (comma-separated)
INDEX_DIRECTORIES=./data,./data/test_docs
```

## ğŸ”Œ API Endpoints

| Endpoint | Method | Purpose |
|----------|--------|---------|
| `/health` | GET | Check if API is alive |
| `/reindex` | POST | Scan and index directories |
| `/ask` | POST | Ask a question |
| `/llm-config` | GET | View configuration |

**Example: Ask a question**
```bash
curl -X POST http://127.0.0.1:8000/ask \
  -H "Content-Type: application/json" \
  -d '{"query": "What is in my files?"}'
```

## ğŸ—‚ï¸ File Format Support

| Format | Extension | Support |
|--------|-----------|---------|
| PDF | `.pdf` | âœ… Full |
| Word | `.docx` | âœ… Full |
| Text | `.txt` | âœ… Full |
| Markdown | `.md` | âœ… Full |
| Images | `.jpg, .png` | â³ Metadata only |

## ğŸ”’ Privacy & Security

âœ… **Completely Private**
- All files indexed locally
- No cloud API calls
- Ollama runs on your machine
- Data never leaves your computer

âœ… **Secure**
- Backend listens only on localhost
- Single machine architecture
- No external dependencies

## ğŸ› Troubleshooting

### Backend won't start
```powershell
# Check Python installation
python --version

# Reinstall dependencies
pip install -r backend/requirements.txt

# Start manually
cd backend
python -m uvicorn app:app --reload
```

### Ollama connection error
```powershell
# Make sure Ollama is running
ollama serve

# Test connection
curl http://localhost:11434/api/tags
```

### Files not indexed
1. Ensure files are in `data/` folder
2. Supported formats only (.txt, .pdf, .docx, .md)
3. Click "Reindex Files" button
4. Check browser console for errors

### UI not loading
```powershell
# Restart UI server
python server.py
# Then open http://localhost:3000
```

### No search results
- Try simpler, more specific keywords
- Make sure files are indexed (click Reindex)
- Use descriptive words from your documents

## ğŸ“Š How It Works

### Indexing Pipeline
```
Your Files (PDFs, DOCX, TXT)
    â†“
Extract Text Content
    â†“
Split into Chunks
    â†“
Create Vector Embeddings (sentence-transformers)
    â†“
Store in ChromaDB
    â†“
Ready for Search!
```

### Query Pipeline
```
Your Question
    â†“
Embed Question
    â†“
Vector Search (find similar docs)
    â†“
Retrieve Top N Results
    â†“
Format with Ollama Prompt
    â†“
Generate Answer Locally (Ollama)
    â†“
Return Answer + Source Files
```

## ğŸ¯ Performance Tips

1. **Fewer, Larger Files** - One 100-page doc is faster than 100 small files
2. **Specific Keywords** - "kubernetes pod security policy" beats "kubernetes"
3. **Organize Folders** - Group related documents in subfolders
4. **Use Reindex Wisely** - Only reindex when you add new files
5. **Pick Right Model** - Mistral is faster, Llama2 is more accurate

## ğŸ§ª Testing

**Test the API directly:**
```powershell
# Health check
curl http://127.0.0.1:8000/health

# Reindex
curl -X POST http://127.0.0.1:8000/reindex

# Ask question
curl -X POST http://127.0.0.1:8000/ask `
  -H "Content-Type: application/json" `
  -d '{"query": "test query"}'
```

## ğŸš€ Advanced Usage

### Using Different Ollama Models

```bash
# List available models
ollama list

# Download new model
ollama pull llama2
ollama pull neural-chat

# Use in .env
OLLAMA_MODEL=llama2
```

### Indexing Large Document Collections

```powershell
# Reindex with more results
# Edit .env: TOP_K_RESULTS=10

# Increase chunk size for faster but less granular search
# Edit .env: CHUNK_SIZE=4000
```

### Custom Directory Structure

```ini
# .env
INDEX_DIRECTORIES=C:/Users/You/Documents,C:/Data/Projects,D:/Archive
```

## ğŸ“ Examples

### Question: "Summarize the architecture"
**Answer from bot:** "Based on your documents, the architecture consists of..."
**Sources:** 
- `C:/Users/VAMSHI/llmlocalai/data/architecture.md`
- `C:/Users/VAMSHI/llmlocalai/data/design-doc.pdf`

### Question: "What are the API endpoints?"
**Answer from bot:** "According to your documentation, the main endpoints are..."
**Sources:**
- `C:/Users/VAMSHI/llmlocalai/data/api-reference.docx`

## ğŸ¤ Contributing

Feel free to submit issues, fork the repository, and create pull requests!

## ğŸ“„ License

MIT License - feel free to use for personal or commercial projects

## ğŸ’¡ Ideas & Improvements

- [ ] Add image OCR support
- [ ] Database search
- [ ] Multi-language support  
- [ ] Custom system prompts
- [ ] Export chat history
- [ ] Plugin system
- [ ] Mobile app
- [ ] Collaborative features

## ğŸ“ Support

1. Check [SETUP_GUIDE.md](SETUP_GUIDE.md) for detailed setup
2. Review terminal output for error messages
3. Ensure Ollama is running
4. Try reindexing your files

## ğŸ‰ You're All Set!

Your local AI chatbot is ready to use:
- ğŸŒ **UI**: http://localhost:3000
- ğŸ”Œ **API**: http://127.0.0.1:8000
- ğŸ“ **Data**: Add files to `data/` folder
- ğŸš€ **Launch**: Double-click `START.bat` or run `START.ps1`

**Happy searching and enjoy your private AI assistant! ğŸš€**

---

Built with â¤ï¸ using FastAPI, ChromaDB, Ollama, and Python
